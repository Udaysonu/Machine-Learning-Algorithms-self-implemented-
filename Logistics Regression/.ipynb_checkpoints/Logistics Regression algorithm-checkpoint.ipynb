{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Logistic Regression Classifier Code by our own\n",
    "###code written by Uday kiran Bakka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "data=pd.read_csv(\"titanic_x_y_train.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.70056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>663</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.70056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.70056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp  Parch     Fare\n",
       "0         2    0  29.00000      1      0  26.0000\n",
       "1         3    1  29.70056      0      0   8.0500\n",
       "2         2    1  39.00000      0      0  26.0000\n",
       "3         3    0  29.00000      0      4  21.0750\n",
       "4         3    1  25.00000      0      0   7.0500\n",
       "..      ...  ...       ...    ...    ...      ...\n",
       "663       2    0  17.00000      0      0  10.5000\n",
       "664       3    1  29.70056      0      0   7.7500\n",
       "665       3    1  32.00000      0      0  56.4958\n",
       "666       3    0  22.00000      0      0   9.8375\n",
       "667       3    0  29.70056      1      0  15.5000\n",
       "\n",
       "[668 rows x 6 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data cleaning if you know cleaning data then don't worry about it****\n",
    "data.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace=True)\n",
    "def change(st):\n",
    "    if st==\"female\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "data[\"Sex\"]=data[\"Sex\"].apply(change)\n",
    "data.drop(\"Embarked\",axis=1,inplace=True)\n",
    "data.Pclass.fillna(data.Pclass.mean(),inplace=True)\n",
    "data.Age.fillna(data.Age.mean(),inplace=True)\n",
    "data.SibSp.fillna(data.SibSp.mean(),inplace=True)\n",
    "data.Parch.fillna(data.Parch.mean(),inplace=True)\n",
    "data.Fare.fillna(data.Fare.mean(),inplace=True)\n",
    "data.Survived.fillna(data.Survived.mean(),inplace=True)\n",
    "y_train=data[\"Survived\"]\n",
    "data.drop(\"Survived\",axis=1,inplace=True)\n",
    "x_train=data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data *****SCALING CONVERGES OUR DATA RAPIDLY WHEN WE APPLY GRADIENT DESCENT*****\n",
    "scalar=StandardScaler()\n",
    "scalar.fit(x_train)\n",
    "x_train=scalar.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number- 1 Cost= 455.04402705722623\n",
      "Iteration Number- 2 Cost= 447.6049792489619\n",
      "Iteration Number- 3 Cost= 440.66347861900056\n",
      "Iteration Number- 4 Cost= 434.18071496654926\n",
      "Iteration Number- 5 Cost= 428.1207414101461\n",
      "Iteration Number- 6 Cost= 422.45039435913037\n",
      "Iteration Number- 7 Cost= 417.1391721442324\n",
      "Iteration Number- 8 Cost= 412.15908692146934\n",
      "Iteration Number- 9 Cost= 407.4845014179673\n",
      "Iteration Number- 10 Cost= 403.0919593082583\n",
      "Iteration Number- 11 Cost= 398.9600156330254\n",
      "Iteration Number- 12 Cost= 395.06907173625785\n",
      "Iteration Number- 13 Cost= 391.40121767866657\n",
      "Iteration Number- 14 Cost= 387.94008393279967\n",
      "Iteration Number- 15 Cost= 384.67070331605237\n",
      "Iteration Number- 16 Cost= 381.5793835103223\n",
      "Iteration Number- 17 Cost= 378.65359009661574\n",
      "Iteration Number- 18 Cost= 375.88183975357526\n",
      "Iteration Number- 19 Cost= 373.253603093659\n",
      "Iteration Number- 20 Cost= 370.7592165106264\n",
      "Iteration Number- 21 Cost= 368.38980236498395\n",
      "Iteration Number- 22 Cost= 366.1371968236057\n",
      "Iteration Number- 23 Cost= 363.99388468366107\n",
      "Iteration Number- 24 Cost= 361.95294054039\n",
      "Iteration Number- 25 Cost= 360.00797569692486\n",
      "Iteration Number- 26 Cost= 358.15309025777486\n",
      "Iteration Number- 27 Cost= 356.3828298927881\n",
      "Iteration Number- 28 Cost= 354.6921468032699\n",
      "Iteration Number- 29 Cost= 353.07636446527994\n",
      "Iteration Number- 30 Cost= 351.5311457660159\n",
      "Iteration Number- 31 Cost= 350.05246418729723\n",
      "Iteration Number- 32 Cost= 348.6365777252167\n",
      "Iteration Number- 33 Cost= 347.2800052670372\n",
      "Iteration Number- 34 Cost= 345.9795051754841\n",
      "Iteration Number- 35 Cost= 344.73205585677493\n",
      "Iteration Number- 36 Cost= 343.5348381123398\n",
      "Iteration Number- 37 Cost= 342.38521909533415\n",
      "Iteration Number- 38 Cost= 341.2807377119884\n",
      "Iteration Number- 39 Cost= 340.21909132474127\n",
      "Iteration Number- 40 Cost= 339.19812362921294\n",
      "Iteration Number- 41 Cost= 338.21581359052647\n",
      "Iteration Number- 42 Cost= 337.2702653364939\n",
      "Iteration Number- 43 Cost= 336.3596989158519\n",
      "Iteration Number- 44 Cost= 335.4824418392643\n",
      "Iteration Number- 45 Cost= 334.6369213293015\n",
      "Iteration Number- 46 Cost= 333.8216572131305\n",
      "Iteration Number- 47 Cost= 333.0352553984263\n",
      "Iteration Number- 48 Cost= 332.27640187899874\n",
      "Iteration Number- 49 Cost= 331.54385722199197\n",
      "Iteration Number- 50 Cost= 330.836451493312\n",
      "Iteration Number- 51 Cost= 330.15307958220274\n",
      "Iteration Number- 52 Cost= 329.4926968897171\n",
      "Iteration Number- 53 Cost= 328.8543153492508\n",
      "Iteration Number- 54 Cost= 328.23699975036857\n",
      "Iteration Number- 55 Cost= 327.63986433989464\n",
      "Iteration Number- 56 Cost= 327.06206967670096\n",
      "Iteration Number- 57 Cost= 326.5028197188427\n",
      "Iteration Number- 58 Cost= 325.9613591236587\n",
      "Iteration Number- 59 Cost= 325.43697074325485\n",
      "Iteration Number- 60 Cost= 324.9289732993932\n",
      "Iteration Number- 61 Cost= 324.43671922323676\n",
      "Iteration Number- 62 Cost= 323.95959264673405\n",
      "Iteration Number- 63 Cost= 323.49700753357274\n",
      "Iteration Number- 64 Cost= 323.0484059387204\n",
      "Iteration Number- 65 Cost= 322.61325638651584\n",
      "Iteration Number- 66 Cost= 322.19105235813987\n",
      "Iteration Number- 67 Cost= 321.78131088010224\n",
      "Iteration Number- 68 Cost= 321.3835712060642\n",
      "Iteration Number- 69 Cost= 320.9973935849908\n",
      "Iteration Number- 70 Cost= 320.62235810918946\n",
      "Iteration Number- 71 Cost= 320.25806363635286\n",
      "Iteration Number- 72 Cost= 319.9041267801706\n",
      "Iteration Number- 73 Cost= 319.5601809645583\n",
      "Iteration Number- 74 Cost= 319.22587553692426\n",
      "Iteration Number- 75 Cost= 318.90087493625754\n",
      "Iteration Number- 76 Cost= 318.58485791219766\n",
      "Iteration Number- 77 Cost= 318.27751679148236\n",
      "Iteration Number- 78 Cost= 317.9785567885157\n",
      "Iteration Number- 79 Cost= 317.68769535701125\n",
      "Iteration Number- 80 Cost= 317.40466157991284\n",
      "Iteration Number- 81 Cost= 317.1291955950062\n",
      "Iteration Number- 82 Cost= 316.8610480538295\n",
      "Iteration Number- 83 Cost= 316.59997961168114\n",
      "Iteration Number- 84 Cost= 316.3457604466609\n",
      "Iteration Number- 85 Cost= 316.09816980586226\n",
      "Iteration Number- 86 Cost= 315.85699557695796\n",
      "Iteration Number- 87 Cost= 315.6220338835342\n",
      "Iteration Number- 88 Cost= 315.39308870268405\n",
      "Iteration Number- 89 Cost= 315.169971503438\n",
      "Iteration Number- 90 Cost= 314.9525009047335\n",
      "Iteration Number- 91 Cost= 314.74050235171086\n",
      "Iteration Number- 92 Cost= 314.5338078092059\n",
      "Iteration Number- 93 Cost= 314.3322554713908\n",
      "Iteration Number- 94 Cost= 314.13568948658155\n",
      "Iteration Number- 95 Cost= 313.9439596963065\n",
      "Iteration Number- 96 Cost= 313.7569213877797\n",
      "Iteration Number- 97 Cost= 313.5744350589924\n",
      "Iteration Number- 98 Cost= 313.39636619567665\n",
      "Iteration Number- 99 Cost= 313.2225850594591\n",
      "Iteration Number- 100 Cost= 313.05296648654837\n",
      "Iteration Number- 101 Cost= 312.88738969636097\n",
      "Iteration Number- 102 Cost= 312.7257381095182\n",
      "Iteration Number- 103 Cost= 312.5678991746856\n",
      "Iteration Number- 104 Cost= 312.4137642037612\n",
      "Iteration Number- 105 Cost= 312.26322821494585\n",
      "Iteration Number- 106 Cost= 312.1161897832703\n",
      "Iteration Number- 107 Cost= 311.9725508981594\n",
      "Iteration Number- 108 Cost= 311.8322168276581\n",
      "Iteration Number- 109 Cost= 311.69509598896656\n",
      "Iteration Number- 110 Cost= 311.56109982493325\n",
      "Iteration Number- 111 Cost= 311.43014268620243\n",
      "Iteration Number- 112 Cost= 311.3021417187115\n",
      "Iteration Number- 113 Cost= 311.1770167562608\n",
      "Iteration Number- 114 Cost= 311.0546902178963\n",
      "Iteration Number- 115 Cost= 310.9350870098457\n",
      "Iteration Number- 116 Cost= 310.81813443179504\n",
      "Iteration Number- 117 Cost= 310.70376208726054\n",
      "Iteration Number- 118 Cost= 310.5919017978744\n",
      "Iteration Number- 119 Cost= 310.4824875213679\n",
      "Iteration Number- 120 Cost= 310.37545527308185\n",
      "Iteration Number- 121 Cost= 310.2707430508236\n",
      "Iteration Number- 122 Cost= 310.16829076291026\n",
      "Iteration Number- 123 Cost= 310.06804015923655\n",
      "Iteration Number- 124 Cost= 309.96993476523426\n",
      "Iteration Number- 125 Cost= 309.8739198185665\n",
      "Iteration Number- 126 Cost= 309.7799422084451\n",
      "Iteration Number- 127 Cost= 309.68795041743016\n",
      "Iteration Number- 128 Cost= 309.59789446560757\n",
      "Iteration Number- 129 Cost= 309.50972585702635\n",
      "Iteration Number- 130 Cost= 309.42339752829605\n",
      "Iteration Number- 131 Cost= 309.3388637992337\n",
      "Iteration Number- 132 Cost= 309.256080325487\n",
      "Iteration Number- 133 Cost= 309.17500405301735\n",
      "Iteration Number- 134 Cost= 309.09559317438243\n",
      "Iteration Number- 135 Cost= 309.01780708672095\n",
      "Iteration Number- 136 Cost= 308.94160635137587\n",
      "Iteration Number- 137 Cost= 308.8669526550698\n",
      "Iteration Number- 138 Cost= 308.79380877257637\n",
      "Iteration Number- 139 Cost= 308.72213853081735\n",
      "Iteration Number- 140 Cost= 308.6519067743219\n",
      "Iteration Number- 141 Cost= 308.5830793319884\n",
      "Iteration Number- 142 Cost= 308.5156229850992\n",
      "Iteration Number- 143 Cost= 308.44950543652305\n",
      "Iteration Number- 144 Cost= 308.3846952810695\n",
      "Iteration Number- 145 Cost= 308.32116197693216\n",
      "Iteration Number- 146 Cost= 308.2588758181852\n",
      "Iteration Number- 147 Cost= 308.1978079082826\n",
      "Iteration Number- 148 Cost= 308.13793013452334\n",
      "Iteration Number- 149 Cost= 308.0792151434387\n",
      "Iteration Number- 150 Cost= 308.02163631706543\n",
      "Iteration Number- 151 Cost= 307.965167750071\n",
      "Iteration Number- 152 Cost= 307.90978422768893\n",
      "Iteration Number- 153 Cost= 307.85546120443956\n",
      "Iteration Number- 154 Cost= 307.8021747835998\n",
      "Iteration Number- 155 Cost= 307.7499016973976\n",
      "Iteration Number- 156 Cost= 307.69861928788856\n",
      "Iteration Number- 157 Cost= 307.64830548850927\n",
      "Iteration Number- 158 Cost= 307.5989388062552\n",
      "Iteration Number- 159 Cost= 307.55049830448604\n",
      "Iteration Number- 160 Cost= 307.5029635863093\n",
      "Iteration Number- 161 Cost= 307.45631477853317\n",
      "Iteration Number- 162 Cost= 307.41053251616756\n",
      "Iteration Number- 163 Cost= 307.36559792744447\n",
      "Iteration Number- 164 Cost= 307.32149261934313\n",
      "Iteration Number- 165 Cost= 307.2781986636008\n",
      "Iteration Number- 166 Cost= 307.23569858318774\n",
      "Iteration Number- 167 Cost= 307.19397533923285\n",
      "Iteration Number- 168 Cost= 307.15301231837714\n",
      "Iteration Number- 169 Cost= 307.11279332055005\n",
      "Iteration Number- 170 Cost= 307.0733025471353\n",
      "Iteration Number- 171 Cost= 307.0345245895348\n",
      "Iteration Number- 172 Cost= 306.99644441809164\n",
      "Iteration Number- 173 Cost= 306.9590473713784\n",
      "Iteration Number- 174 Cost= 306.9223191458285\n",
      "Iteration Number- 175 Cost= 306.8862457856979\n",
      "Iteration Number- 176 Cost= 306.85081367334885\n",
      "Iteration Number- 177 Cost= 306.8160095198407\n",
      "Iteration Number- 178 Cost= 306.7818203558179\n",
      "Iteration Number- 179 Cost= 306.7482335226887\n",
      "Iteration Number- 180 Cost= 306.71523666407467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number- 181 Cost= 306.6828177175336\n",
      "Iteration Number- 182 Cost= 306.6509649065332\n",
      "Iteration Number- 183 Cost= 306.61966673268057\n",
      "Iteration Number- 184 Cost= 306.5889119681852\n",
      "Iteration Number- 185 Cost= 306.5586896485567\n",
      "Iteration Number- 186 Cost= 306.5289890655286\n",
      "Iteration Number- 187 Cost= 306.49979976019125\n",
      "Iteration Number- 188 Cost= 306.47111151633766\n",
      "Iteration Number- 189 Cost= 306.4429143540137\n",
      "Iteration Number- 190 Cost= 306.41519852325604\n",
      "Iteration Number- 191 Cost= 306.38795449801995\n",
      "Iteration Number- 192 Cost= 306.36117297029375\n",
      "Iteration Number- 193 Cost= 306.33484484438344\n",
      "Iteration Number- 194 Cost= 306.3089612313668\n",
      "Iteration Number- 195 Cost= 306.28351344371475\n",
      "Iteration Number- 196 Cost= 306.25849299007024\n",
      "Iteration Number- 197 Cost= 306.2338915701776\n",
      "Iteration Number- 198 Cost= 306.20970106996344\n",
      "Iteration Number- 199 Cost= 306.185913556761\n",
      "Iteration Number- 200 Cost= 306.1625212746694\n",
      "Iteration Number- 201 Cost= 306.1395166400527\n",
      "Iteration Number- 202 Cost= 306.11689223716155\n",
      "Iteration Number- 203 Cost= 306.09464081389046\n",
      "Iteration Number- 204 Cost= 306.0727552776436\n",
      "Iteration Number- 205 Cost= 306.05122869133277\n",
      "Iteration Number- 206 Cost= 306.03005426947647\n",
      "Iteration Number- 207 Cost= 306.0092253744173\n",
      "Iteration Number- 208 Cost= 305.9887355126436\n",
      "Iteration Number- 209 Cost= 305.9685783312141\n",
      "Iteration Number- 210 Cost= 305.94874761428326\n",
      "Iteration Number- 211 Cost= 305.92923727972436\n",
      "Iteration Number- 212 Cost= 305.9100413758452\n",
      "Iteration Number- 213 Cost= 305.8911540781946\n",
      "Iteration Number- 214 Cost= 305.8725696864601\n",
      "Iteration Number- 215 Cost= 305.85428262144677\n",
      "Iteration Number- 216 Cost= 305.8362874221452\n",
      "Iteration Number- 217 Cost= 305.81857874286953\n",
      "Iteration Number- 218 Cost= 305.8011513504858\n",
      "Iteration Number- 219 Cost= 305.7840001217074\n",
      "Iteration Number- 220 Cost= 305.76712004046374\n",
      "Iteration Number- 221 Cost= 305.7505061953467\n",
      "Iteration Number- 222 Cost= 305.7341537771183\n",
      "Iteration Number- 223 Cost= 305.71805807628897\n",
      "Iteration Number- 224 Cost= 305.70221448075995\n",
      "Iteration Number- 225 Cost= 305.68661847352803\n",
      "Iteration Number- 226 Cost= 305.6712656304533\n",
      "Iteration Number- 227 Cost= 305.65615161808273\n",
      "Iteration Number- 228 Cost= 305.64127219153545\n",
      "Iteration Number- 229 Cost= 305.62662319243555\n",
      "Iteration Number- 230 Cost= 305.61220054691154\n",
      "Iteration Number- 231 Cost= 305.598000263637\n",
      "Iteration Number- 232 Cost= 305.5840184319283\n",
      "Iteration Number- 233 Cost= 305.5702512198894\n",
      "Iteration Number- 234 Cost= 305.55669487260514\n",
      "Iteration Number- 235 Cost= 305.5433457103829\n",
      "Iteration Number- 236 Cost= 305.53020012703587\n",
      "Iteration Number- 237 Cost= 305.51725458821437\n",
      "Iteration Number- 238 Cost= 305.5045056297776\n",
      "Iteration Number- 239 Cost= 305.4919498562064\n",
      "Iteration Number- 240 Cost= 305.4795839390593\n",
      "Iteration Number- 241 Cost= 305.4674046154643\n",
      "Iteration Number- 242 Cost= 305.4554086866511\n",
      "Iteration Number- 243 Cost= 305.4435930165183\n",
      "Iteration Number- 244 Cost= 305.43195453023986\n",
      "Iteration Number- 245 Cost= 305.42049021290376\n",
      "Iteration Number- 246 Cost= 305.4091971081832\n",
      "Iteration Number- 247 Cost= 305.3980723170474\n",
      "Iteration Number- 248 Cost= 305.3871129964953\n",
      "Iteration Number- 249 Cost= 305.37631635833014\n",
      "Iteration Number- 250 Cost= 305.36567966795474\n",
      "Iteration Number- 251 Cost= 305.35520024320675\n",
      "Iteration Number- 252 Cost= 305.3448754532112\n",
      "Iteration Number- 253 Cost= 305.3347027172725\n",
      "Iteration Number- 254 Cost= 305.3246795037843\n",
      "Iteration Number- 255 Cost= 305.3148033291697\n",
      "Iteration Number- 256 Cost= 305.3050717568503\n",
      "Iteration Number- 257 Cost= 305.2954823962331\n",
      "Iteration Number- 258 Cost= 305.2860329017278\n",
      "Iteration Number- 259 Cost= 305.2767209717857\n",
      "Iteration Number- 260 Cost= 305.2675443479606\n",
      "Iteration Number- 261 Cost= 305.25850081399443\n",
      "Iteration Number- 262 Cost= 305.2495881949226\n",
      "Iteration Number- 263 Cost= 305.24080435620095\n",
      "Iteration Number- 264 Cost= 305.23214720285677\n",
      "Iteration Number- 265 Cost= 305.223614678654\n",
      "Iteration Number- 266 Cost= 305.21520476528275\n",
      "Iteration Number- 267 Cost= 305.2069154815665\n",
      "Iteration Number- 268 Cost= 305.1987448826871\n",
      "Iteration Number- 269 Cost= 305.1906910594308\n",
      "Iteration Number- 270 Cost= 305.1827521374464\n",
      "Iteration Number- 271 Cost= 305.1749262765267\n",
      "Iteration Number- 272 Cost= 305.1672116699042\n",
      "Iteration Number- 273 Cost= 305.15960654355973\n",
      "Iteration Number- 274 Cost= 305.1521091555543\n",
      "Iteration Number- 275 Cost= 305.14471779536996\n",
      "Iteration Number- 276 Cost= 305.13743078326735\n",
      "Iteration Number- 277 Cost= 305.1302464696613\n",
      "Iteration Number- 278 Cost= 305.12316323450705\n",
      "Iteration Number- 279 Cost= 305.1161794867002\n",
      "Iteration Number- 280 Cost= 305.10929366349364\n",
      "Iteration Number- 281 Cost= 305.10250422992493\n",
      "Iteration Number- 282 Cost= 305.0958096782566\n",
      "Iteration Number- 283 Cost= 305.08920852743256\n",
      "Iteration Number- 284 Cost= 305.0826993225403\n",
      "Iteration Number- 285 Cost= 305.0762806342934\n",
      "Iteration Number- 286 Cost= 305.0699510585167\n",
      "Iteration Number- 287 Cost= 305.06370921565036\n",
      "Iteration Number- 288 Cost= 305.0575537502623\n",
      "Iteration Number- 289 Cost= 305.0514833305697\n",
      "Iteration Number- 290 Cost= 305.0454966479738\n",
      "Iteration Number- 291 Cost= 305.0395924166022\n",
      "Iteration Number- 292 Cost= 305.0337693728658\n",
      "Iteration Number- 293 Cost= 305.028026275019\n",
      "Iteration Number- 294 Cost= 305.02236190273885\n",
      "Iteration Number- 295 Cost= 305.01677505669903\n",
      "Iteration Number- 296 Cost= 305.0112645581709\n",
      "Iteration Number- 297 Cost= 305.00582924861845\n",
      "Iteration Number- 298 Cost= 305.00046798930845\n",
      "Iteration Number- 299 Cost= 304.99517966093146\n",
      "Iteration Number- 300 Cost= 304.9899631632242\n"
     ]
    }
   ],
   "source": [
    "#class of Logistic Regression which contains all the algorithms\n",
    "class LogisticRegression:\n",
    "    #pass number of iterations and learning rate\n",
    "    #since my data is already scaled i am applying it=300 and lr=0.1\n",
    "    #******If your data is different or you did not apply scaling then your data needs different it and lr values\n",
    "    def __init__(self,it=300,lr=0.1):\n",
    "        self.learning_rate=lr\n",
    "        self.iterations=it\n",
    "        self.m=None\n",
    "    #function which applies gradient descent\n",
    "    def GradientDescent(self,x,y,m_slope):\n",
    "        new_m=np.zeros(shape=len(x[0]))\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x[0])):  \n",
    "                #funtion sigma [i from 1 to len(x) ] (y_i-h(mTx)).x_i\n",
    "                new_m[j]+=(y[i]-(self.sigmoid(sum(m_slope*x[i]))))*x[i][j]\n",
    "        #new_m_slope=m_slope-(learning_rate)*d(m_slope)/d(m_j)\n",
    "        return m_slope+(1/len(x))*self.learning_rate*new_m\n",
    "    \n",
    "    #sigmoid funciton\n",
    "    def sigmoid(self,x):\n",
    "        a  =  1.0/(1+np.exp(-x))\n",
    "        return a\n",
    "    \n",
    "    #cost function which finds the cost\n",
    "    def cost(self,x,y,m_slope):\n",
    "        value=0 \n",
    "        for i in range(len(x)):\n",
    "            mtxi=sum(m_slope*x[i])\n",
    "            # sigma[i from 1 to len(x)](log(1+exp(mTx)-y_i))\n",
    "            value+=abs(np.log(1+np.exp(mtxi))-y[i]*mtxi)\n",
    "\n",
    "        return value\n",
    "    #function when calls gradient descent and stores slope valuse\n",
    "    def fit(self,x_train,y_train):\n",
    "        ones=np.ones(shape=(len(x_train),1))\n",
    "        x_train=np.append(x_train,ones,axis=1)\n",
    "        m_slope=np.array([0 for i in range(len(x_train[0]))])\n",
    "        for i in range(self.iterations):\n",
    "            m_slope=self.GradientDescent(x_train,y_train,m_slope)\n",
    "            z=self.cost(x_train,y_train,m_slope)\n",
    "            print(\"Iteration Number-\",i+1,\"Cost=\",z)\n",
    "        self.m=m_slope\n",
    "    \n",
    "    #funciton which predicts the output\n",
    "    def predict(self,x):\n",
    "        y_pred=[]\n",
    "        ones=np.ones(shape=(len(x),1))\n",
    "        x=np.append(x,ones,axis=1)\n",
    "        for i in range(len(x)):\n",
    "            if self.sigmoid(sum(x[i]*self.m))>=0.5:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        return y_pred\n",
    "\n",
    "#callig our inbuilt Logistic regression classifier\n",
    "lr=LogisticRegression()\n",
    "#fitting our training data\n",
    "lr.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[338,  61],\n",
       "       [ 79, 190]], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lr.predict(np.array(x_train))\n",
    "#predicting our own classifier and calculating its accuracy using confusion matrix\n",
    "confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[336  63]\n",
      " [ 80 189]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uday sonu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#calling inbuilt Logistic Regression classifier to check whether our answer is same as it or not\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred=clf.predict(x_train)\n",
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##we could see that our classifier is working more accurate than the inbuilt classifier\n",
    "##enjoy and keep coding :)\n",
    "#code written by Uday kiran Bakka"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
